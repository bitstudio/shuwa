{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from knn_data_generator import KNNDataGenerator\n",
    "from losses import Losses\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "def get_JCD(frames_batched):\n",
    "    \n",
    "    # distance matrix.\n",
    "    d_m = batch_frames_cdist(frames_batched, frames_batched)\n",
    "    d_m = tf.reshape(d_m, (-1, d_m.shape[1], d_m.shape[2]* d_m.shape[3]))   \n",
    "    \n",
    "    return d_m\n",
    "\n",
    "\n",
    "# input shape [batch, 32, 13, 2]\n",
    "def batch_frames_cdist(a, b):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(a, 2) - tf.expand_dims(b, 3)), axis=-1))\n",
    "\n",
    "\n",
    "# input shape [batch, 32, 13, 2]\n",
    "def pose_motion(raw_poses):\n",
    "    diff_slow = poses_diff(raw_poses)\n",
    "    # flatten last 2 dims.\n",
    "    diff_slow = tf.reshape(diff_slow, (-1, diff_slow.shape[1], diff_slow.shape[2]*diff_slow.shape[3]))\n",
    "    \n",
    "    # jump frame\n",
    "    fast = raw_poses[:, ::2, :, :]  \n",
    "    diff_fast = poses_diff(fast)\n",
    "    # flatten last 2 dims.\n",
    "    diff_fast = tf.reshape(diff_fast, (-1, diff_fast.shape[1], diff_fast.shape[2]*diff_fast.shape[3]))\n",
    "    \n",
    "    return diff_slow, diff_fast   \n",
    "\n",
    "\n",
    "def poses_diff(x):    \n",
    "    # frame t - frame(t-1)\n",
    "    x = x[:, 1:, :, :] - x[:, :-1, :, :]     \n",
    "    x_d = tf.expand_dims(x[:, 0, :, :], 1)\n",
    "    x_d = tf.concat([x_d, x], axis=1)\n",
    "\n",
    "    return x_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "def c1D(x, filters, kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU(shared_axes=[1])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block(x, filters):\n",
    "    x = c1D(x, filters, 3)\n",
    "    x = c1D(x, filters, 3)\n",
    "    return x\n",
    "\n",
    "\n",
    "def d1D(x, filters):\n",
    "    x = Dense(filters, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU(shared_axes=[1])(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "#pose encoder\n",
    "def encode_jcds(x, filters, drop_out=0.4):\n",
    "    x = c1D(x, filters*2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x, filters, 1)\n",
    "    x = MaxPooling1D(2)(x)     \n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# hands encoder\n",
    "def joints_encoder(filters, drop_out=0.4):\n",
    "    encoder_input = Input(shape=(NUM_FRAME_SAMPLES, 441))\n",
    "    x = c1D(encoder_input, filters*2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x, filters, 1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "    \n",
    "    return Model(inputs=encoder_input, outputs=x)\n",
    "\n",
    "\n",
    "def encode_diff_slow(diff_slow, filters):\n",
    "    x_d_slow = c1D(diff_slow, filters*2, 1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow, filters, 3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow, filters, 1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)      \n",
    "    \n",
    "    return x_d_slow\n",
    "\n",
    "def encode_diff_fast(diff_fast, filters):\n",
    "    x_d_fast = c1D(diff_fast, filters*2, 1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast, filters, 3)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast, filters, 1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    \n",
    "    return x_d_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "def build_backbone(\n",
    "                    pose_frames,\n",
    "                    diff_slow, diff_fast,\n",
    "                    face_frames,\n",
    "                    left_hand_frames, right_hand_frames,\n",
    "                    filters):\n",
    "\n",
    "    \n",
    "    # pose\n",
    "    pose_encoded = encode_jcds(pose_frames, filters//2, drop_out=0.4)    \n",
    "    pose_encoded = c1D(pose_encoded, 256, 3)\n",
    "    pose_encoded = MaxPooling1D(4)(pose_encoded)\n",
    "    pose_encoded = c1D(pose_encoded, 256, 3)\n",
    "    pose_encoded = MaxPooling1D(2)(pose_encoded)   \n",
    "    pose_encoded= Flatten()(pose_encoded)\n",
    "    pose_encoded = Dense(256)(pose_encoded)\n",
    "    pose_encoded = tf.math.l2_normalize(pose_encoded, axis=-1)\n",
    "        \n",
    "        \n",
    "    # face\n",
    "    face_encoded = encode_jcds(face_frames, filters//2, drop_out=0.3)    \n",
    "    face_encoded = c1D(face_encoded, 128, 3)\n",
    "    face_encoded = MaxPooling1D(4)(face_encoded)\n",
    "    face_encoded = c1D(face_encoded, 128, 3)\n",
    "    face_encoded = MaxPooling1D(2)(face_encoded) \n",
    "    face_encoded= Flatten()(face_encoded)\n",
    "    face_encoded = Dense(64)(face_encoded)\n",
    "    face_encoded = tf.math.l2_normalize(face_encoded, axis=-1)\n",
    "    \n",
    "    # hands\n",
    "    diff_slow_encoded = encode_diff_slow(diff_slow, filters)\n",
    "    diff_fast_encoded = encode_diff_fast(diff_fast, filters)\n",
    "    hand_encoder = joints_encoder(int(filters*4), drop_out=0.4)   \n",
    "    left_hands_encoded = hand_encoder(left_hand_frames)\n",
    "    right_hands_encoded = hand_encoder(right_hand_frames)\n",
    "    hands = concatenate([diff_slow_encoded, diff_fast_encoded, left_hands_encoded, right_hands_encoded])\n",
    "    hands = c1D(hands, 256, 3)\n",
    "    hands = MaxPooling1D(4)(hands)\n",
    "    hands = c1D(hands, 512, 3)\n",
    "    hands = MaxPooling1D(2)(hands)   \n",
    "    hands = Flatten()(hands)\n",
    "    hands = Dense(512)(hands)   \n",
    "    hands = tf.math.l2_normalize(hands, axis=-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # all feats\n",
    "    x = concatenate([pose_encoded, face_encoded, hands])\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "def build_DD_Net():       \n",
    "    # input layers.\n",
    "    pose_frames_input = Input(shape=(NUM_FRAME_SAMPLES, NUM_SELECTED_POSENET_JOINTS, POSENET_JOINT_DIMS), name='pose_frames_input')\n",
    "    face_frames_input = Input(shape=(NUM_FRAME_SAMPLES, NUM_SELECTED_FACE_JOINTS, FACE_JOINT_DIMS), name='face_frames_input')\n",
    "    left_hand_frames_input = Input(shape=(NUM_FRAME_SAMPLES, NUM_HAND_JOINTS, HAND_JOINT_DIMS), name='left_hand_frames_input')\n",
    "    right_hand_frames_input = Input(shape=(NUM_FRAME_SAMPLES, NUM_HAND_JOINTS, HAND_JOINT_DIMS), name='right_hand_frames_input')\n",
    "    \n",
    "    # poses                 \n",
    "    pose_frames_jcds = get_JCD(pose_frames_input)      \n",
    "    \n",
    "    hand_cat = concatenate([left_hand_frames_input, right_hand_frames_input], axis=-2)    \n",
    "    \n",
    "    diff_slow, diff_fast = pose_motion(hand_cat)    \n",
    "    \n",
    "    \n",
    "    # faces\n",
    "    face_frames = get_JCD(face_frames_input)\n",
    "\n",
    "    \n",
    "    # hands\n",
    "    left_hand_frames = get_JCD(left_hand_frames_input)\n",
    "    right_hand_frames = get_JCD(right_hand_frames_input)\n",
    " \n",
    "\n",
    "        \n",
    "\n",
    "    # embed and backbone.\n",
    "    x = build_backbone(pose_frames_jcds,\n",
    "                       diff_slow, diff_fast,\n",
    "                       face_frames,\n",
    "                       left_hand_frames, right_hand_frames,\n",
    "                       filters=NUM_START_FILTERS)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    model = Model(inputs=[pose_frames_input, face_frames_input, left_hand_frames_input, right_hand_frames_input], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "batch_size = 1\n",
    "pose_frames_input = Input(batch_shape=(batch_size, NUM_FRAME_SAMPLES, NUM_SELECTED_POSENET_JOINTS, POSENET_JOINT_DIMS), name='pose_frames_input')\n",
    "face_frames_input = Input(batch_shape=(batch_size, NUM_FRAME_SAMPLES, NUM_SELECTED_FACE_JOINTS, FACE_JOINT_DIMS), name='face_frames_input')\n",
    "left_hand_frames_input = Input(batch_shape=(batch_size, NUM_FRAME_SAMPLES, NUM_HAND_JOINTS, HAND_JOINT_DIMS), name='left_hand_frames_input')\n",
    "right_hand_frames_input = Input(batch_shape=(batch_size, NUM_FRAME_SAMPLES, NUM_HAND_JOINTS, HAND_JOINT_DIMS), name='right_hand_frames_input')\n",
    "\n",
    "embedder_model = build_DD_Net()\n",
    "\n",
    "# embed.\n",
    "feats_out = embedder_model([pose_frames_input, face_frames_input, left_hand_frames_input, right_hand_frames_input])\n",
    "cls_out = Dense(100, activation=\"softmax\", name=\"cls_out\")(feats_out)\n",
    "\n",
    "\n",
    "model = Model(inputs=[pose_frames_input, face_frames_input,\n",
    "                      left_hand_frames_input, right_hand_frames_input],\n",
    "              outputs=[feats_out, cls_out])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = KNNDataGenerator('D:/jobs/datasets/video/sign_language/kps/train',\n",
    "                                     batch_size=batch_size, use_augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_generator = KNNDataGenerator('D:/jobs/datasets/video/sign_language/kps/val',\n",
    "                                     batch_size=32, use_augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "acc_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "loss = Losses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "source": [
    "start train model using hard example mining."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_train_step(image_batch, feats_true, cls_true):   \n",
    "    with tf.GradientTape() as tape:\n",
    "        feats_pred, cls_pred = model(image_batch, training=True)\n",
    "        loss((feats_true, cls_true), (feats_pred, cls_pred)) \n",
    "    \n",
    "    grads = tape.gradient(loss.total_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))   \n",
    "    acc_metrics.update_state(cls_true, cls_pred)  \n",
    "   \n",
    "   \n",
    "\n",
    "initial_epoch = 0\n",
    "max_epoch = 1000\n",
    "steps_per_epoch = 500\n",
    "\n",
    "for _epoch in range(initial_epoch, max_epoch):   \n",
    "    dh = display(\"\" ,display_id=True)\n",
    "    \n",
    "    for _step in range(steps_per_epoch):\n",
    "        image_batch, [feats_true, cls_true] = train_generator.__getitem__(0)     \n",
    "        \n",
    "\n",
    "        custom_train_step(image_batch, feats_true, cls_true)\n",
    "         \n",
    "        # hard example mining.\n",
    "        hard_samples = tf.argsort(loss.cls_loss).numpy()[-2*batch_size//10:]\n",
    "        train_generator.update_hard_count(feats_true[hard_samples])\n",
    "         \n",
    "                \n",
    "        # print.        \n",
    "        dh.update(\"epoch-{:02d} step-{:02d} triplet_loss-{:.4f} cls_loss-{:.4f} acc-{:.4f}\"\\\n",
    "                  .format(_epoch, _step, loss.triplet_loss, loss.cls_loss_mean, acc_metrics.result().numpy()))                \n",
    "        _step += 1 \n",
    "   \n",
    "                  \n",
    "                  \n",
    "    triplet_avg, cls_avg = loss.calc_avg()\n",
    "    dh.update(\"epoch-{:02d} triplet_avg-{:.4f} cls_avg-{:.4f} acc-{:.2f}\".format(_epoch, triplet_avg, cls_avg, acc_metrics.result().numpy()))    \n",
    "    filepath = \"checkpoints/slow-{:02d}-{:.4f}-{:.4f}-{:.2f}.h5\".format(_epoch, triplet_avg, cls_avg, acc_metrics.result().numpy())\n",
    "    model.save(filepath)\n",
    "    acc_metrics.reset_states()\n",
    "    \n",
    "    \n",
    "    train_generator.update_hard_idxs()\n",
    "    model.evaluate(val_generator)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('checkpoints_knn/0108.h5', include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "187.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}